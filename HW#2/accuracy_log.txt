Epoch 1: Train accuracy: 0.9587, Test accuracy: 0.9604
train loss:2.299273649777335
=== epoch:1, train acc:0.125, test acc:0.136 ===
train loss:2.298270266050508
train loss:2.2934058562219284
train loss:2.284681484801553
train loss:2.2815775045831264
train loss:2.2753859982307074
train loss:2.260215443107558
train loss:2.2544082347180123
train loss:2.229568274273751
train loss:2.201384701758507
train loss:2.1604859364235898
train loss:2.1148390490583937
train loss:2.1067219256389778
train loss:2.027084101535529
train loss:2.0045245220921277
train loss:1.9354574403071383
train loss:1.8893485239764096
train loss:1.7753109028087477
train loss:1.6694301274297738
train loss:1.698595842598026
train loss:1.565654275241704
train loss:1.5667393813348176
train loss:1.4862937411568629
train loss:1.3807951288150346
train loss:1.3557780744296963
train loss:1.1859505185251606
train loss:1.1748263028897907
train loss:1.0653203875963209
train loss:1.0044681033931089
train loss:0.9100471293888872
train loss:0.8431274109526312
train loss:0.9489761663365907
train loss:0.7175533695429175
train loss:0.862649655633729
train loss:0.7353896617358493
train loss:0.7512826005741353
train loss:0.6859789220644396
train loss:0.563279128001911
train loss:0.6059858692906908
train loss:0.5466718300210089
train loss:0.5967981210398292
train loss:0.6076490150410206
train loss:0.4893767587798956
train loss:0.6400325392921532
train loss:0.5092068412458364
train loss:0.4967810180557106
train loss:0.55265565193347
train loss:0.4858923625343738
train loss:0.7741975094931846
train loss:0.5710396505275104
train loss:0.5678637880882057
=== epoch:2, train acc:0.806, test acc:0.77 ===
train loss:0.4413605453244984
train loss:0.45449989525668977
train loss:0.4454794476267851
train loss:0.4197352602630374
train loss:0.40190587107203607
train loss:0.24456842590667244
train loss:0.5349368284430642
train loss:0.8252380145414261
train loss:0.6308333175906217
train loss:0.38773884927946894
train loss:0.5485778760337124
train loss:0.4460051231868658
train loss:0.5091214596126745
train loss:0.6401929830471851
train loss:0.5521208920597909
train loss:0.2876034829601044
train loss:0.46854368260524076
train loss:0.29962750507921515
train loss:0.39024599956551226
train loss:0.45020672193446853
train loss:0.4529636357502846
train loss:0.3183884688037613
train loss:0.3250407383700968
train loss:0.34847604535501175
train loss:0.4120326758954803
train loss:0.34513289745365505
train loss:0.30806092993681616
train loss:0.4912445302049258
train loss:0.3813548078552414
train loss:0.5151507111707534
train loss:0.2549295687366931
train loss:0.3098343534498858
train loss:0.4585437002902545
train loss:0.21105310057558038
train loss:0.4057188840167136
train loss:0.5236980827779993
train loss:0.27504341074090527
train loss:0.35342704851923146
train loss:0.4361070220384277
train loss:0.5027927417334046
train loss:0.45598270094392523
train loss:0.18790987787337887
train loss:0.25922659728848874
train loss:0.4292126155359172
train loss:0.39759576287514065
train loss:0.28750993617244136
train loss:0.4800556538074647
train loss:0.3568562209450402
train loss:0.21495888858254283
train loss:0.36650571284506145
=== epoch:3, train acc:0.872, test acc:0.859 ===
train loss:0.3709457873589114
train loss:0.3136211050976359
train loss:0.26055497578823905
train loss:0.421655720076301
train loss:0.2654141322390606
train loss:0.3118928217255927
train loss:0.18553104763383094
train loss:0.37309610468458154
train loss:0.3153055843387278
train loss:0.2597137865540178
train loss:0.12360428400076819
train loss:0.2989120499788561
train loss:0.2372510791615563
train loss:0.4420815452628561
train loss:0.2726939842054128
train loss:0.3343982946832623
train loss:0.2988748142448047
train loss:0.30485222970627524
train loss:0.25336125846073326
train loss:0.1812870323444988
train loss:0.275350551419395
train loss:0.41186600266216966
train loss:0.38997374087038544
train loss:0.277381729910627
train loss:0.2771476081791883
train loss:0.2187658001301526
train loss:0.4082907679575052
train loss:0.2908544018183893
train loss:0.21947260944110958
train loss:0.2246996865734413
train loss:0.47765302322606634
train loss:0.25938037771488026
train loss:0.34132048111116764
train loss:0.22739584419093425
train loss:0.5115132617146211
train loss:0.16953393093730437
train loss:0.2797668397128184
train loss:0.20008786715253532
train loss:0.2352925109512411
train loss:0.25781850271667733
train loss:0.23774112172087045
train loss:0.23785080909528683
train loss:0.2899824213187475
train loss:0.2531788490548773
train loss:0.28063777495769715
train loss:0.23675293914184375
train loss:0.2712010249466579
train loss:0.2656301255157045
train loss:0.2567451836941251
train loss:0.26129372766983605
=== epoch:4, train acc:0.909, test acc:0.9 ===
train loss:0.24993173122344106
train loss:0.15663428194264614
train loss:0.3177458053015943
train loss:0.24469326925752227
train loss:0.31009132906960407
train loss:0.3255105412120116
train loss:0.24404819842853345
train loss:0.2768265820775109
train loss:0.18868792283913993
train loss:0.14694175294345485
train loss:0.20727687620697569
train loss:0.150691213903593
train loss:0.23896590582420538
train loss:0.1385013812003084
train loss:0.18694687187041226
train loss:0.11767819647988143
train loss:0.1672848465889133
train loss:0.2840713389371175
train loss:0.29136688326183124
train loss:0.2124607611817694
train loss:0.2081757107698722
train loss:0.14358226065366317
train loss:0.2097667899989088
train loss:0.22106072337360796
train loss:0.38580945793814997
train loss:0.14148367839032475
train loss:0.26380415866617635
train loss:0.22143931128913774
train loss:0.13821341652034771
train loss:0.2418855200764796
train loss:0.2540325706304274
train loss:0.30083462271895045
train loss:0.26948145306527166
train loss:0.20132852906046442
train loss:0.2877118348943126
train loss:0.1500167205151317
train loss:0.21910638500849638
train loss:0.2344750609872517
train loss:0.2622010405502856
train loss:0.10815000991799067
train loss:0.3403617755558799
train loss:0.24597239462111734
train loss:0.2352262282755717
train loss:0.11417075524022983
train loss:0.1620738799631067
train loss:0.37163715458232593
train loss:0.20834022788275713
train loss:0.21127276424468192
train loss:0.27434979572034907
train loss:0.13157666346636598
=== epoch:5, train acc:0.923, test acc:0.909 ===
train loss:0.23879019462010045
train loss:0.11107573420315385
train loss:0.23312789169314044
train loss:0.24962219593993176
train loss:0.25990927167155875
train loss:0.12451818753263874
train loss:0.15443286241301277
train loss:0.21510122551407496
train loss:0.2174361748320776
train loss:0.13904783190529116
train loss:0.15768848270752892
train loss:0.1660559639825551
train loss:0.3505593466354561
train loss:0.1358460118821002
train loss:0.2978218399180325
train loss:0.14687482234080346
train loss:0.14891004461619742
train loss:0.12362014097935184
train loss:0.1731224035937636
train loss:0.23788937661583057
train loss:0.18099116556790754
train loss:0.16132423178570496
train loss:0.12635333772051072
train loss:0.12946969151865068
train loss:0.2613970789404964
train loss:0.12759953478917757
train loss:0.13184659572981983
train loss:0.19497316449424099
train loss:0.22701749890381012
train loss:0.12253074512119014
train loss:0.13049235707538054
train loss:0.219120996220055
train loss:0.2206186062708462
train loss:0.14255531771271107
train loss:0.10895530087876003
train loss:0.26472258218717554
train loss:0.22576426330389876
train loss:0.261374464588336
train loss:0.07962210723905236
train loss:0.16792236353652895
train loss:0.09211334277051617
train loss:0.18553594403986837
train loss:0.12381032202842647
train loss:0.1381609400968253
train loss:0.2052392235112075
train loss:0.09490962884592599
train loss:0.25922772239841196
train loss:0.21229996436413134
train loss:0.08914715590198066
train loss:0.16438489161910178
=== epoch:6, train acc:0.941, test acc:0.92 ===
train loss:0.2310823493226213
train loss:0.10056287124695462
train loss:0.21433590233013844
train loss:0.13850348930227055
train loss:0.1288142902049688
train loss:0.19054204182691578
train loss:0.1989695810522478
train loss:0.21188811805422364
train loss:0.2901208759025278
train loss:0.1574662880030203
train loss:0.09685271463507471
train loss:0.2458737101112022
train loss:0.19746782779979657
train loss:0.17664958783476728
train loss:0.12349627416880854
train loss:0.14560026104054008
train loss:0.1312135700265845
train loss:0.14280261017080517
train loss:0.19785504340352206
train loss:0.2248622513540971
train loss:0.16633058531623376
train loss:0.19373068967295395
train loss:0.10965900806928718
train loss:0.14317046615382337
train loss:0.17268597332965677
train loss:0.130845819072294
train loss:0.10209759633662774
train loss:0.15611484399730535
train loss:0.1544157514721251
train loss:0.11710951458791
train loss:0.1313652044079133
train loss:0.08242326326091887
train loss:0.16978478465538172
train loss:0.18372161101641768
train loss:0.10281428437204797
train loss:0.2616458525584988
train loss:0.16902765756334978
train loss:0.11875326242530457
train loss:0.09974031838909761
train loss:0.1604525980374628
train loss:0.1922476354514986
train loss:0.3119856080719234
train loss:0.12266957517398787
train loss:0.16087640802987022
train loss:0.08575265672849294
train loss:0.23994954109304012
train loss:0.08389478492300452
train loss:0.13658342199004797
train loss:0.19219160191407691
train loss:0.09570167803023462
=== epoch:7, train acc:0.937, test acc:0.927 ===
train loss:0.0826060111857746
train loss:0.11586523214569076
train loss:0.18294379709019232
train loss:0.13541956977104197
train loss:0.21124626933241117
train loss:0.1849676034348067
train loss:0.16369750946378445
train loss:0.10921781932802842
train loss:0.10795618207182574
train loss:0.13051765707349555
train loss:0.08746889978407109
train loss:0.13123860427664227
train loss:0.1545511512569239
train loss:0.14430665729384096
train loss:0.11979496958683206
train loss:0.1046295482125048
train loss:0.2407397020012071
train loss:0.07839860334145977
train loss:0.15498415296864956
train loss:0.15426284059443862
train loss:0.1315293455706819
train loss:0.08587270154004223
train loss:0.15668499578153944
train loss:0.12311751204071948
train loss:0.12498998258924889
train loss:0.09661592346631767
train loss:0.25566040315336486
train loss:0.13456644450126848
train loss:0.13091315440665421
train loss:0.11280572165501032
train loss:0.18768066369276665
train loss:0.18303254295088306
train loss:0.17865781947511788
train loss:0.20178046550467016
train loss:0.1682652039403203
train loss:0.07311998649110713
train loss:0.1607737620028452
train loss:0.07336331257487588
train loss:0.13085250181397734
train loss:0.16540981257293633
train loss:0.09931772980431618
train loss:0.11446165747535492
train loss:0.12746773985173063
train loss:0.1382914556037912
train loss:0.11274574418850705
train loss:0.10157584031781709
train loss:0.24284027321706592
train loss:0.09942932481218822
train loss:0.18793070039446516
train loss:0.07099607660926355
=== epoch:8, train acc:0.953, test acc:0.943 ===
train loss:0.043057744096843355
train loss:0.059325489228774744
train loss:0.15764644908681227
train loss:0.0793332995412188
train loss:0.060256748608435544
train loss:0.13233452862146827
train loss:0.09549775161526482
train loss:0.16412368856337647
train loss:0.06239838438366675
train loss:0.09599509088153656
train loss:0.14518626308025057
train loss:0.06844983358571428
train loss:0.10569820611316227
train loss:0.10199720373836094
train loss:0.07984605856771163
train loss:0.11774219511107611
train loss:0.1335765792284324
train loss:0.0614127285630998
train loss:0.11667045876102788
train loss:0.08438605968708224
train loss:0.09717833137349448
train loss:0.14787286351250117
train loss:0.050829163080478905
train loss:0.09908004158503361
train loss:0.16060274440504022
train loss:0.10384993780019842
train loss:0.05173513211631628
train loss:0.05234250523506479
train loss:0.1438041490847108
train loss:0.09201926824414879
train loss:0.05843698480715773
train loss:0.0850045665230259
train loss:0.08121045191039
train loss:0.06520112832083881
train loss:0.0772285399384712
train loss:0.0887303525147917
train loss:0.13115687301863263
train loss:0.10850177082415362
train loss:0.09720811196372738
train loss:0.04366303577766027
train loss:0.08220639412653115
train loss:0.054219912711119894
train loss:0.07634915843397977
train loss:0.05227474981660074
train loss:0.06916568830940757
train loss:0.10322690172760518
train loss:0.03848330390435053
train loss:0.1651418571055242
train loss:0.08425948874756056
train loss:0.07064822267147575
=== epoch:9, train acc:0.962, test acc:0.938 ===
train loss:0.06301313239949698
train loss:0.05529273210942955
train loss:0.19619348318111665
train loss:0.12148321065106177
train loss:0.12465620664200537
train loss:0.15334870479140872
train loss:0.04482812506968063
train loss:0.08787536486797777
train loss:0.0588551938528928
train loss:0.14287317642729594
train loss:0.10680228216444158
train loss:0.10985211320447184
train loss:0.07179897170824007
train loss:0.07097801864775147
train loss:0.04970584288525596
train loss:0.09939575234265391
train loss:0.07649735251861656
train loss:0.08301486090741594
train loss:0.1737996901181449
train loss:0.07694700887148581
train loss:0.05840421415177231
train loss:0.10010678219920015
train loss:0.10961010892451782
train loss:0.1070814104425434
train loss:0.10093534250857322
train loss:0.07305152113539376
train loss:0.02677709676064361
train loss:0.11514444768719885
train loss:0.08313697525632793
train loss:0.12574742956063728
train loss:0.10484075188861308
train loss:0.06772233146256983
train loss:0.05832291782342807
train loss:0.11427573675708215
train loss:0.06594161027111996
train loss:0.09504410952271422
train loss:0.04627274658278118
train loss:0.08835003196324553
train loss:0.048258966067849
train loss:0.037288092827275514
train loss:0.06840818398302488
train loss:0.10599276892605922
train loss:0.13136279189674352
train loss:0.1484129093475438
train loss:0.08570780093678432
train loss:0.08548231081228624
train loss:0.06534176813742702
train loss:0.09479122554442718
train loss:0.027765843111467507
train loss:0.08251643475343991
=== epoch:10, train acc:0.969, test acc:0.948 ===
train loss:0.06913648065384265
train loss:0.04338895443660586
train loss:0.03531932648385441
train loss:0.04531409201225722
train loss:0.1590676329288935
train loss:0.117721913636221
train loss:0.14262732279496912
train loss:0.08849295863272316
train loss:0.05449937106473291
train loss:0.034537474553450756
train loss:0.1666161648961897
train loss:0.056642808136061006
train loss:0.04835052255614384
train loss:0.11506893588068019
train loss:0.04870694509536684
train loss:0.05450329496428208
train loss:0.041915697509146976
train loss:0.06526591234031826
train loss:0.10288866480459574
train loss:0.028884827688435793
train loss:0.04082402704669822
train loss:0.12202386554284067
train loss:0.08005624562431017
train loss:0.08644974139123013
train loss:0.13370042335874466
train loss:0.05757590266221294
train loss:0.051652165388350026
train loss:0.029845441592933605
train loss:0.05861238396279388
train loss:0.10263593859511541
train loss:0.05276874392292788
train loss:0.061018732013244016
train loss:0.1802617608249982
train loss:0.0466284495122267
train loss:0.07260780449723223
train loss:0.1447160325021293
train loss:0.06087552096591686
train loss:0.07225738127344394
train loss:0.1840024868507911
train loss:0.11270196375558057
train loss:0.0615074750665058
train loss:0.1292875389709897
train loss:0.12276701330447587
train loss:0.06141927408282524
train loss:0.08285123108496244
train loss:0.0633760292587089
train loss:0.09462384579981231
train loss:0.07569507011963618
train loss:0.057779775452704955
train loss:0.03069034349568838
=== epoch:11, train acc:0.97, test acc:0.947 ===
train loss:0.035423546168301
train loss:0.07600701213686198
train loss:0.10825107493146875
train loss:0.07232478970113668
train loss:0.05259355194896945
train loss:0.08312612010186403
train loss:0.03850415431346854
train loss:0.16040609175867004
train loss:0.06775194387685243
train loss:0.09827269105144743
train loss:0.03682294299030196
train loss:0.04649255628526992
train loss:0.037722554207314116
train loss:0.1009306510889462
train loss:0.04804977738488232
train loss:0.03743410108857653
train loss:0.1612740755522024
train loss:0.03164760747320416
train loss:0.05099473069119249
train loss:0.08601242668536146
train loss:0.07935589548052996
train loss:0.06842490009518892
train loss:0.06341865657288871
train loss:0.06427186229061388
train loss:0.05159897757027032
train loss:0.03199560852856162
train loss:0.11246093911222464
train loss:0.10518646328137154
train loss:0.035326310199480015
train loss:0.05728832436989287
train loss:0.057478148985107384
train loss:0.05986547474584078
train loss:0.03996523258084796
train loss:0.09509192585082916
train loss:0.04696697000945305
train loss:0.05051016818566672
train loss:0.11022363720255088
train loss:0.027906799400803962
train loss:0.18636509028871426
train loss:0.037490861813288215
train loss:0.09239297718903415
train loss:0.017237353677384555
train loss:0.09355205443159799
train loss:0.035179100640835716
train loss:0.051388524040447595
train loss:0.154246291135964
train loss:0.05882830213442862
train loss:0.10321458859500104
train loss:0.030227661365983965
train loss:0.031192425189495606
=== epoch:12, train acc:0.976, test acc:0.951 ===
train loss:0.03382853284013001
train loss:0.05862072530687835
train loss:0.1684904818895677
train loss:0.053261216807735046
train loss:0.1106717951534894
train loss:0.07574769447148713
train loss:0.05308064391142242
train loss:0.08701020555568122
train loss:0.08394517563793005
train loss:0.04939763695910262
train loss:0.07456549096814863
train loss:0.07615297963144861
train loss:0.04257019321174447
train loss:0.11354023807894809
train loss:0.10495024895910347
train loss:0.04026846477115008
train loss:0.05966979911355092
train loss:0.039434033313770864
train loss:0.05757373776033727
train loss:0.0727981803364936
train loss:0.040229310648198006
train loss:0.03525385969382894
train loss:0.041542213122426286
train loss:0.015055842224348373
train loss:0.0792089764230351
train loss:0.04320268599292632
train loss:0.10523523292833906
train loss:0.04052014545622133
train loss:0.028066574493526633
train loss:0.08486783653508677
train loss:0.09328152430528007
train loss:0.03280173157942647
train loss:0.019806785947718075
train loss:0.08575613848248906
train loss:0.03203454187339784
train loss:0.027429902027248546
train loss:0.07899959377360967
train loss:0.06898460356391033
train loss:0.058269273298706924
train loss:0.02279712756102232
train loss:0.05610379512490631
train loss:0.05120870712822654
train loss:0.062409390219439545
train loss:0.052345738480348764
train loss:0.09589741196943802
train loss:0.06785135208676764
train loss:0.030721049953926848
train loss:0.015434620877370622
train loss:0.02435993842663578
train loss:0.06188704489003553
=== epoch:13, train acc:0.983, test acc:0.959 ===
train loss:0.06266154956016391
train loss:0.017425803699367373
train loss:0.052379725981223084
train loss:0.031774707496678885
train loss:0.0374401541161814
train loss:0.03679191072706281
train loss:0.047198641106090185
train loss:0.026085608218236328
train loss:0.056265784360867495
train loss:0.03254288437838424
train loss:0.04783605926869737
train loss:0.08331346979892426
train loss:0.06382943357390232
train loss:0.023928583623692372
train loss:0.05258477317699408
train loss:0.04704218122517262
train loss:0.11492593301544134
train loss:0.030976023299622832
train loss:0.02808999852342188
train loss:0.018747228004485722
train loss:0.07823284336771354
train loss:0.06900001646899216
train loss:0.08837107123903053
train loss:0.0728732110234243
train loss:0.019174845529012097
train loss:0.02706799541527409
train loss:0.055185909218527146
train loss:0.1125452541583969
train loss:0.06046028316141476
train loss:0.022778687806132635
train loss:0.04211155747723469
train loss:0.10677096453239945
train loss:0.014112138628771097
train loss:0.05197597101513703
train loss:0.06306415672045165
train loss:0.049514580989990196
train loss:0.040601952126069873
train loss:0.03228384583346542
train loss:0.09715297420563664
train loss:0.02095546796107779
train loss:0.02950588213285086
train loss:0.028874244110468066
train loss:0.043727098150660934
train loss:0.058436278360068136
train loss:0.0534144520628398
train loss:0.02845881600724171
train loss:0.08868417342744146
train loss:0.046687431131851025
train loss:0.1338872784813513
train loss:0.08576221172007266
=== epoch:14, train acc:0.98, test acc:0.96 ===
train loss:0.04156630495283755
train loss:0.010159686946135109
train loss:0.06385771887953914
train loss:0.014091506506181493
train loss:0.05424845854250135
train loss:0.048104388168494806
train loss:0.036109763906757186
train loss:0.011978946764566765
train loss:0.029801215441522956
train loss:0.021236381516091668
train loss:0.02456931422981944
train loss:0.0353858842864233
train loss:0.05356961732994949
train loss:0.017199044918665144
train loss:0.10972163557364162
train loss:0.011402165460305303
train loss:0.08292723617630951
train loss:0.08072926596544018
train loss:0.020508633220698756
train loss:0.0787191793835411
train loss:0.02455638937659087
train loss:0.023202840338650787
train loss:0.036735136335431906
train loss:0.02418851216420054
train loss:0.035225533588783095
train loss:0.0706355901151424
train loss:0.02503609469311055
train loss:0.04401201468551094
train loss:0.023409772295286766
train loss:0.10559092357003212
train loss:0.029798546891536125
train loss:0.04393129360264987
train loss:0.015045649777568943
train loss:0.040690658056609104
train loss:0.038888106606641076
train loss:0.030757396458760897
train loss:0.0504641959832495
train loss:0.03903555062390964
train loss:0.019283694667332037
train loss:0.03149619210690284
train loss:0.022806265919991967
train loss:0.053885923053016614
train loss:0.07517335484561044
train loss:0.06421465277230098
train loss:0.08585407749762722
train loss:0.09950868570475381
train loss:0.01781723240366927
train loss:0.020410428201302632
train loss:0.03228750653339194
train loss:0.035965394918945286
=== epoch:15, train acc:0.989, test acc:0.958 ===
train loss:0.035351928098773244
train loss:0.048417854216441125
train loss:0.057590237229096015
train loss:0.017490083394334267
train loss:0.01231358427657671
train loss:0.0729584123704615
train loss:0.020635712626285167
train loss:0.03130707071220757
train loss:0.04515495848509941
train loss:0.040825131057760304
train loss:0.04322513595808312
train loss:0.015051483505162786
train loss:0.015615664899535357
train loss:0.03243960034038341
train loss:0.032495368514381597
train loss:0.061097441009064016
train loss:0.03495350408432754
train loss:0.08585722095301426
train loss:0.015411166514749886
train loss:0.03484947681208121
train loss:0.030323112663160748
train loss:0.10584857333686092
train loss:0.060072849967774414
train loss:0.03999960441244829
train loss:0.07535770028280823
train loss:0.0215972292978695
train loss:0.019464429994617453
train loss:0.019227564153699854
train loss:0.05276998025429136
train loss:0.03203380057284131
train loss:0.021597251295964914
train loss:0.03943781701822344
train loss:0.02779163666039191
train loss:0.028384263967332592
train loss:0.07428543913432414
train loss:0.017473232052911805
train loss:0.011704611807974528
train loss:0.04191665722262619
train loss:0.07114960597057861
train loss:0.0259561991340934
train loss:0.02660689226174776
train loss:0.0463725171400385
train loss:0.0249313501188656
train loss:0.05412695413838053
train loss:0.01697440519115642
train loss:0.026771661131551036
train loss:0.013852583883031616
train loss:0.027897657319563524
train loss:0.03207807794375715
train loss:0.01961870618366901
=== epoch:16, train acc:0.992, test acc:0.959 ===
train loss:0.045198634912506266
train loss:0.015843470548129564
train loss:0.022801605961038484
train loss:0.0253321845084475
train loss:0.01743694088718107
train loss:0.021900200579418706
train loss:0.017735009421124926
train loss:0.019379294434683267
train loss:0.015373870131776306
train loss:0.04945354428557307
train loss:0.019433144053142417
train loss:0.05040462944151126
train loss:0.04083448595088393
train loss:0.03085118604777652
train loss:0.015462050957044672
train loss:0.04832837632571657
train loss:0.007560791404537204
train loss:0.028667566032887563
train loss:0.050223077082428055
train loss:0.042722512108635716
train loss:0.013287751507553397
train loss:0.030917561917536106
train loss:0.018757653105123097
train loss:0.015280444669451594
train loss:0.07346245740286382
train loss:0.0507706683839664
train loss:0.019986769693400665
train loss:0.033556748297083515
train loss:0.03922450242116923
train loss:0.027697573706022657
train loss:0.03309701515426832
train loss:0.025019602676110565
train loss:0.018285062753683856
train loss:0.009761488927186509
train loss:0.07031910663212458
train loss:0.041063068572531176
train loss:0.04370742653155336
train loss:0.04785819844169554
train loss:0.05715702280896868
train loss:0.02620632449100925
train loss:0.01910927472434965
train loss:0.01778789049473215
train loss:0.025329738298591288
train loss:0.05017814789064884
train loss:0.014661421837012904
train loss:0.04698698943884998
train loss:0.005449120790101174
train loss:0.03656983650151648
train loss:0.021515968551246697
train loss:0.02707062157120417
=== epoch:17, train acc:0.99, test acc:0.959 ===
train loss:0.025773764893604435
train loss:0.02648157690154213
train loss:0.006865524045569376
train loss:0.12886292974971103
train loss:0.0427708404585449
train loss:0.02044233118679106
train loss:0.007340114796671749
train loss:0.008690246946548637
train loss:0.024583652628149332
train loss:0.07192238127938802
train loss:0.027258278818710683
train loss:0.07264484934079121
train loss:0.021797940407401618
train loss:0.05033303899679051
train loss:0.02477970144113146
train loss:0.027758461111593757
train loss:0.010828178951156849
train loss:0.023723074337882354
train loss:0.019414568485147124
train loss:0.023361434262723826
train loss:0.016721979607941445
train loss:0.02331651968665344
train loss:0.026681328974678988
train loss:0.018277373052043216
train loss:0.020525620243404163
train loss:0.06390490419278008
train loss:0.023644542054871147
train loss:0.01566924672159413
train loss:0.047158914354797084
train loss:0.03061099658678079
train loss:0.02727998876945353
train loss:0.02717644974857228
train loss:0.016222097282889734
train loss:0.041916668850634095
train loss:0.0073093586926258934
train loss:0.034015109664905105
train loss:0.023313340096766003
train loss:0.03036746499549108
train loss:0.0202002157259868
train loss:0.006999977453587361
train loss:0.01429889658053211
train loss:0.0107173059490751
train loss:0.02028134862228598
train loss:0.019488278880290068
train loss:0.01972590324301218
train loss:0.015041103925762774
train loss:0.01385111900651011
train loss:0.010813367501118125
train loss:0.040686790410316684
train loss:0.006628555596093869
=== epoch:18, train acc:0.99, test acc:0.962 ===
train loss:0.02753343138155744
train loss:0.008298893853856482
train loss:0.007861222743331509
train loss:0.009448932310875324
train loss:0.027833296414351293
train loss:0.019360130531895267
train loss:0.06116364909385814
train loss:0.056587847323887726
train loss:0.031039611639452618
train loss:0.04860867423527518
train loss:0.0814367738800408
train loss:0.060072318244791624
train loss:0.03274427320534728
train loss:0.03478337253521843
train loss:0.008692011656870358
train loss:0.02851210926631653
train loss:0.019047798292172565
train loss:0.040142290085564136
train loss:0.026826304440363203
train loss:0.019081881336080308
train loss:0.035618820790264405
train loss:0.011203735611074017
train loss:0.014866734820877936
train loss:0.010352913888194273
train loss:0.0265762669344257
train loss:0.033829827355494224
train loss:0.012306402675686966
train loss:0.031288025586614296
train loss:0.009525238775077088
train loss:0.03673036342227427
train loss:0.027505012946704394
train loss:0.010414062949998392
train loss:0.03581495195706855
train loss:0.03615790120461599
train loss:0.02487501532613321
train loss:0.039141613838056616
train loss:0.020790145331982025
train loss:0.014534251871753385
train loss:0.012152435170300669
train loss:0.02092912949365124
train loss:0.00797171868946907
train loss:0.031079550553379826
train loss:0.020249565952340537
train loss:0.01754356942606554
train loss:0.02211158223202558
train loss:0.011951360287310711
train loss:0.02537373882873414
train loss:0.051587652499089594
train loss:0.0832110517345002
train loss:0.01748423225906052
=== epoch:19, train acc:0.996, test acc:0.963 ===
train loss:0.004775462169130195
train loss:0.008493761809896245
train loss:0.011182521975579802
train loss:0.017092855300601097
train loss:0.009984092751151441
train loss:0.016112054079668724
train loss:0.025227359281745153
train loss:0.016426837118851827
train loss:0.01587903931071012
train loss:0.007733257130981813
train loss:0.03806169808038859
train loss:0.028855851636701183
train loss:0.010683780738889648
train loss:0.022333039913127836
train loss:0.028518882053257096
train loss:0.013307707202557847
train loss:0.005794846394530258
train loss:0.009679444506161495
train loss:0.018205916424979592
train loss:0.0453497441020813
train loss:0.010735837889551444
train loss:0.02210950275665382
train loss:0.01043157245532777
train loss:0.010598050409826571
train loss:0.019021192277820707
train loss:0.00993805315348654
train loss:0.007523809273186037
train loss:0.014160202176090753
train loss:0.017613824758012816
train loss:0.01627463810784588
train loss:0.014820981300947578
train loss:0.014807604815449696
train loss:0.01965427445391438
train loss:0.03449606349301411
train loss:0.03482502352548402
train loss:0.011142337999366314
train loss:0.010696202143073406
train loss:0.009805417454432423
train loss:0.02701184174582957
train loss:0.035931822807741834
train loss:0.00949263286051795
train loss:0.006125510812317131
train loss:0.01819082179156943
train loss:0.02731959101898683
train loss:0.06618565896118289
train loss:0.02545750808424309
train loss:0.05349321483344784
train loss:0.014781463634775139
train loss:0.007797687725196764
train loss:0.029881901746366502
=== epoch:20, train acc:0.994, test acc:0.959 ===
train loss:0.016704756518690477
train loss:0.03628256405013776
train loss:0.04016875263952973
train loss:0.012701641832086276
train loss:0.009100605662433169
train loss:0.013360339874325633
train loss:0.005538845686580076
train loss:0.011390908906959318
train loss:0.012705826566257954
train loss:0.007701785533761524
train loss:0.015589788534343825
train loss:0.06380552304219975
train loss:0.01653211663255448
train loss:0.018675700771515154
train loss:0.0056631528729724386
train loss:0.015355628328670165
train loss:0.010157201678287632
train loss:0.009098460077242482
train loss:0.03158148088822209
train loss:0.028786837674244534
train loss:0.008791116857585834
train loss:0.010420605242109984
train loss:0.01389190167987629
train loss:0.01211065503154772
train loss:0.008621076792979626
train loss:0.01188550300481627
train loss:0.005810595424519215
train loss:0.014843155338708749
train loss:0.005513805047318502
train loss:0.006656506621427423
train loss:0.02268729078642697
train loss:0.006828596684895211
train loss:0.007072165406085037
train loss:0.027206939501831978
train loss:0.007242065539016761
train loss:0.010448602893097944
train loss:0.014686157252679667
train loss:0.004931318742150699
train loss:0.016223304286279515
train loss:0.007552205944833063
train loss:0.012945008183450658
train loss:0.014064981532275119
train loss:0.009973833573340593
train loss:0.009260217271458598
train loss:0.007755273991731359
train loss:0.010143933526087357
train loss:0.0098796876101432
train loss:0.045584499651474084
train loss:0.0074650752366733075
=============== Final Test Accuracy ===============
test acc:0.96
